# -*- coding: utf-8 -*-
"""step4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1amZEyKDCFvEfuMPkXVqOz30zd9IZSF9m
"""

import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_auc_score, average_precision_score, roc_curve, confusion_matrix

import matplotlib.pyplot as plt

DATA_PATH = "customer_pd_dataset.csv"
df = pd.read_csv(DATA_PATH)

# If your CSV doesn't contain default_flag_v3 yet, create it here (v3 rule):
if "default_flag_v3" not in df.columns:
    df["default_flag_v3"] = np.where(
        (df["return_rate"] >= 0.40) |
        ((df["return_rate"] >= 0.20) & (df["total_profit"] < 0) & (df["avg_discount"] >= 0.30)),
        1, 0
    )

print("Bad rate:", df["default_flag_v3"].mean())
df.head()

TARGET = "default_flag_v3"

leakage_features = [
    "return_rate",
    "avg_discount",
    "total_profit"
]

numeric_cols = [
    c for c in df.columns
    if c != TARGET
    and pd.api.types.is_numeric_dtype(df[c])
    and c not in leakage_features
]

X = df[numeric_cols].copy()
y = df[TARGET].astype(int).copy()

print("Features used (leakage-safe):", numeric_cols)

time_col_candidates = [c for c in df.columns if "date" in c.lower() or "month" in c.lower()]

if len(time_col_candidates) > 0:
    time_col = time_col_candidates[0]
    print("Using time column:", time_col)

    tmp = df.copy()
    tmp[time_col] = pd.to_datetime(tmp[time_col], errors="coerce")
    tmp = tmp.sort_values(time_col)

    split_idx = int(len(tmp) * 0.80)
    train_idx = tmp.index[:split_idx]
    test_idx  = tmp.index[split_idx:]

    X_train, y_train = X.loc[train_idx], y.loc[train_idx]
    X_test,  y_test  = X.loc[test_idx],  y.loc[test_idx]
else:
    print("No time column found â†’ using stratified random split (document as limitation).")
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.20, random_state=42, stratify=y
    )

print("Train bad rate:", y_train.mean())
print("Test bad rate :", y_test.mean())

numeric_transformer = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="median")),
    ("scaler", StandardScaler())
])

preprocess = ColumnTransformer(
    transformers=[("num", numeric_transformer, numeric_cols)],
    remainder="drop"
)

model = LogisticRegression(
    penalty="l2",
    C=1.0,               # regularization strength (tune later)
    solver="lbfgs",
    max_iter=2000,
    class_weight="balanced"
)

clf = Pipeline(steps=[
    ("preprocess", preprocess),
    ("model", model)
])

clf

clf.fit(X_train, y_train)

pd_train = clf.predict_proba(X_train)[:, 1]
pd_test  = clf.predict_proba(X_test)[:, 1]

print("Train PD range:", (pd_train.min(), pd_train.max()))
print("Test  PD range:", (pd_test.min(), pd_test.max()))

auc = roc_auc_score(y_test, pd_test)
prauc = average_precision_score(y_test, pd_test)

print(f"ROC-AUC: {auc:.4f}")
print(f"PR-AUC : {prauc:.4f}")

fpr, tpr, thresholds = roc_curve(y_test, pd_test)
ks = np.max(tpr - fpr)
ks_threshold = thresholds[np.argmax(tpr - fpr)]

print(f"KS: {ks:.4f}")
print(f"KS threshold: {ks_threshold:.4f}")

plt.figure()
plt.plot(thresholds, tpr - fpr)
plt.title("KS curve (TPR - FPR) vs Threshold")
plt.xlabel("Threshold")
plt.ylabel("KS")
plt.grid(True, alpha=0.3)
plt.show()

chosen_threshold = ks_threshold

y_pred = (pd_test >= chosen_threshold).astype(int)
cm = confusion_matrix(y_test, y_pred)

print("Confusion matrix at KS threshold:")
print(cm)

eval_df = pd.DataFrame({"pd": pd_test, "y": y_test.values})
eval_df["decile"] = pd.qcut(eval_df["pd"], 10, duplicates="drop")

cal = eval_df.groupby("decile").agg(
    n=("y","size"),
    avg_pd=("pd","mean"),
    observed_dr=("y","mean")
).reset_index()

cal

plt.figure()
plt.plot(cal["avg_pd"], cal["observed_dr"], marker="o")
plt.plot([0, cal["avg_pd"].max()], [0, cal["avg_pd"].max()], linestyle="--")
plt.title("Calibration (Deciles): Predicted PD vs Observed Default Rate")
plt.xlabel("Average predicted PD")
plt.ylabel("Observed default rate")
plt.grid(True, alpha=0.3)
plt.show()

# Get feature names and coefficients
feature_names = numeric_cols
coefs = clf.named_steps["model"].coef_[0]

coef_df = pd.DataFrame({
    "feature": feature_names,
    "coef": coefs
}).sort_values("coef", ascending=False)

coef_df